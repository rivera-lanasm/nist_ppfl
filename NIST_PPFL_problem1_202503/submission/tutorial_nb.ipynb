{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new current working directory path\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path.cwd().parent)\n",
    "print('CWD After: ', Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "# ART membership inference helper methods \n",
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "# pre trained models \n",
    "from problem1.attack_targets.cnn.model import Net as cnn_Net\n",
    "from problem1.attack_targets.dpcnn10.model import Net as dpcnn10_Net\n",
    "from problem1.attack_targets.dpcnn200.model import Net as dpcnn200_Net\n",
    "\n",
    "# helper methods\n",
    "from utils import load_model, load_data, load_path_set, build_attack_model, eval_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIST Genomics PPFL Red Team Exercise\n",
    "### Introductory tutorial for performing Membership Inference Attack on CNN trained on Soybean Genomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID_SET = ['1', '2', '3', '4']\n",
    "challenge_pred_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'dpcnn'  # 'dpcnn' or 'cnn'\n",
    "PRIVACY_TYPE = 'dpcnn200'  # 'cnn' (no privacy), 'dpcnn10' (epsilon 10), dpcnn200 (epsilon 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to challenge records data file for the client model\n",
    "model_dir = Path(f'problem1/attack_targets/{PRIVACY_TYPE}')\n",
    "challenge_data_path = Path(model_dir, f'{PRIVACY_TYPE}_challenge_records.dat')\n",
    "print(challenge_data_path)\n",
    "# Challenge records are those for which the competitor need to classify. \n",
    "#   Each challenge record can be classified into 5 categories.\n",
    "#   If a challenge record belongs to the client model, the competitor should classify it as the client number (1, 2, 3, or 4). \n",
    "#   Otherwise, the competitor should classify it as 0 --> which means the record does not belong to any client model in the selected privacy level / privacy type.\n",
    "challenge_x, challenge_y = load_data(challenge_data_path)\n",
    "print(\"shape, challenge records: {}\".format(challenge_x.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id in CLIENT_ID_SET:\n",
    "    print(\"Process attack model for client {}\".format(int(client_id)))\n",
    "    # load data and pre-trained model paths\n",
    "    model_path, relevant_data_path, external_data_path, hyperparameters_path = load_path_set(privacy_type=PRIVACY_TYPE, \n",
    "                                                                                                                  client_id=client_id, \n",
    "                                                                                                                  model_type=MODEL_TYPE)\n",
    "    \n",
    "    # Relevant records are those which an attacker might believe belongs to the client model. \n",
    "    rel_x, rel_y = load_data(relevant_data_path)\n",
    "    print(relevant_data_path)\n",
    "    print(\"shape, relevant records: {}\".format(rel_x.shape))\n",
    "\n",
    "    # External records are those which an attacker believes do not belong to the client model. See problem statement for details.\n",
    "    ext_x, ext_y = load_data(external_data_path)\n",
    "    print(external_data_path)\n",
    "    print(\"shape, external records: {}\".format(ext_x.shape))\n",
    "    print(\"==========\\n\")\n",
    "\n",
    "    # load architecture for pre-trained clients (target of MI attack)\n",
    "    if PRIVACY_TYPE == \"cnn\":\n",
    "        model_class = cnn_Net\n",
    "    elif PRIVACY_TYPE == \"dpcnn10\":\n",
    "        model_class = dpcnn10_Net\n",
    "    elif PRIVACY_TYPE == \"dpcnn200\":\n",
    "        model_class = dpcnn200_Net\n",
    "    else:\n",
    "        raise ValueError(\"invalid model type\")\n",
    "\n",
    "    task_model = load_model(model_path=model_path, \n",
    "                            num_data_features=rel_x.shape[1], \n",
    "                            model_class=model_class)\n",
    "\n",
    "    # build attack model\n",
    "    attack_model = build_attack_model(task_model=task_model,\n",
    "                                      num_data_features=rel_x.shape[1], \n",
    "                                      hyperparameters_path=hyperparameters_path)\n",
    "    \n",
    "\n",
    "    # Get client model's predictions on relevant and external data\n",
    "    rel_x_preds = task_model(rel_x).squeeze()\n",
    "    ext_x_preds = task_model(ext_x).squeeze()\n",
    "    rel_x_preds = rel_x_preds.detach().numpy()\n",
    "    ext_x_preds = ext_x_preds.detach().numpy()\n",
    "    \n",
    "    # challenge data predictions\n",
    "    challenge_pred = eval_model(rel_x_preds, ext_x_preds, rel_y, ext_y, attack_model, rel_x, ext_x, challenge_x, challenge_y)\n",
    "    # assign \n",
    "    challenge_pred_set.append(challenge_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(challenge_pred_set):\n",
    "    plt.figure()\n",
    "    pd.Series(val.reshape(1,-1)[0]).hist()\n",
    "    plt.title(f\"Histogram for attach model for client {i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack them into a single array of shape (4, N)\n",
    "stacked = np.stack(challenge_pred_set, axis=0)\n",
    "\n",
    "# Get the maximum value and index across arrays \n",
    "max_values = np.max(stacked, axis=0)\n",
    "max_indices = np.argmax(stacked, axis=0)\n",
    "\n",
    "# Apply condition: only keep indices where max value >= 0.5\n",
    "result_indices = np.where(max_values >= 0.5, max_indices, 4)\n",
    "\n",
    "# reshape \n",
    "result_indices = result_indices.reshape(1,-1)[0]\n",
    "# for formatting, add 1 and then mod 5 to each resulting val\n",
    "    # we we want \"5\" to map to 0 (meaning no attack model is not confident)  \n",
    "result_indices = (result_indices + 1) % 5\n",
    "\n",
    "result_indices = result_indices.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return output format\n",
    "output = pd.DataFrame({\"index\":np.arange(result_indices.shape[0]), \"prediction\":result_indices})\n",
    "\n",
    "if PRIVACY_TYPE == \"cnn\":\n",
    "    file_name = \"cnn_submission_file\"\n",
    "elif PRIVACY_TYPE == \"dpcnn10\":\n",
    "    file_name = \"dpcnn10_submission_file\"\n",
    "elif PRIVACY_TYPE == \"dpcnn200\":\n",
    "    file_name = \"dpcnn200_submission_file\"\n",
    "\n",
    "print(file_name)\n",
    "output.to_csv(\"{}.csv\".format(file_name), index=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's see how good this approach is for client 4 across the three privacy conditions\n",
    "\n",
    "- We have access to the indices from the challenge records corresponding to client #4 across the 3 privacy conditions\n",
    "- So correctly identifying these records indicates how good our client 4 model is relative to the other models \n",
    "- perhaps we don't just care that we **correctly** identify these records as corresponding to client 4 - we care about the ratio of the client 4 prediction vs the average of the predictions in favor of the other 3 clients \n",
    "    - value close to 1 indicates that we don't have very high confidence \n",
    "    - value greater than 1 indicates higher confidence \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Records\n",
    "\n",
    "**CNN: No DP**\n",
    "\n",
    "**CNN: DP, 10**\n",
    "\n",
    "**CNN: DP, 200**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Records\n",
    "\n",
    "**CNN: No DP**\n",
    "\n",
    "**CNN: DP, 10**\n",
    "\n",
    "**CNN: DP, 200**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Challenge member indices and relevant member indices\n",
    "challenge_members_path = Path(f'problem1/attack_targets/{PRIVACY_TYPE}/client_{client_id}', f'{MODEL_TYPE}_4_challenge_members.json')\n",
    "\n",
    "with open(challenge_members_path, 'r') as f:\n",
    "    challenge_members_dict = json.load(f)\n",
    "\n",
    "challenge_members = list(challenge_members_dict['challenge members'])\n",
    "\n",
    "print(\"number of positive instances among challenge members: {}\".format(len(challenge_members)))\n",
    "\n",
    "# Get true client 4 members in challenge data\n",
    "true_client_4_members_x = challenge_x[challenge_members]\n",
    "true_client_4_members_y = challenge_y[challenge_members]\n",
    "\n",
    "# ==============================================\n",
    "# Infer membership on true client 4 members\n",
    "preds = attack_model.infer(x=true_client_4_members_x, y=true_client_4_members_y)\n",
    "true_members_correct = np.sum((preds == 1))\n",
    "# Calculate percentage of predicting true members as members by the attack model\n",
    "true_members_percentage = (true_members_correct / len(preds)) * 100\n",
    "print('Positive Class Recall In Challenge Records: ', f'{round(true_members_percentage, 2)}%')\n",
    "# confidence\n",
    "\n",
    "# ==============================================\n",
    "# but did we correctly **reject** non client 4 members?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppflenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
